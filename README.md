# ü¶é Chameleon: GPT-5 Robustness Testing Framework

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![OpenAI API](https://img.shields.io/badge/OpenAI-GPT--5-green.svg)](https://openai.com/api/)

A comprehensive framework for testing large language model robustness under lexical distortion. The Chameleon project systematically evaluates GPT-5's performance across 20 academic subjects with varying levels of lexical perturbation (Œº = 0.0 to 0.9).

## üéØ Project Overview

The Chameleon framework addresses a critical question in AI evaluation: **How robust are large language models to lexical variations in input text?** By applying controlled lexical distortions to academic assessment questions, I can measure model performance degradation and identify vulnerable domains.

### Key Features

- üî¨ **Systematic Distortion Testing**: 10 distortion levels (Œº = 0.0 to 0.9)
- üìö **Multi-Domain Coverage**: 20 academic subjects from medicine to mathematics
- ü§ñ **GPT-5 Integration**: Automated batch processing via OpenAI API
- üìä **Comprehensive Analysis**: Statistical evaluation with visualizations
- üîÑ **Reproducible Pipeline**: End-to-end automation with quality assurance

## üìä Key Results

- **18,200 questions processed** with 100% completion
- **85.8% overall accuracy** across all conditions
- **15.4% performance drop** from baseline to maximum distortion
- **97.4% format consistency** maintained under distortion

## üöÄ Quick Start

### Prerequisites

```bash
# Required Python packages
pip install -r requirements.txt

# OpenAI API key
export OPENAI_API_KEY="your-api-key-here"
```

### Basic Usage

```bash
# 1. Prepare distorted questions (if needed)
python3 chameleon.py --generate-distortions

# 2. Process with GPT-5 (if needed)
python3 gpt5_manager.py submit --auto

# 3. Monitor progress (if needed)
python3 gpt5_manager.py monitor

# 4. Clean and validate answers
python3 clean_gpt5_answers.py

# 5. Generate visualizations
python3 create_visualizations.py

# 6. Run statistical analysis
python3 statistical_analysis.py
```

## üèóÔ∏è Architecture

### Core Components

```
Chameleon/
‚îú‚îÄ‚îÄ üìÅ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                          # Project configuration
‚îú‚îÄ‚îÄ üìÅ modules/
‚îÇ   ‚îú‚îÄ‚îÄ data_preparation.py                  # Question preparation and distortion
‚îÇ   ‚îú‚îÄ‚îÄ gpt5_batch_processor.py             # Batch processing logic
‚îÇ   ‚îî‚îÄ‚îÄ mistral_server.py                   # Distortion generation server
‚îú‚îÄ‚îÄ üìÅ batches/
‚îÇ   ‚îú‚îÄ‚îÄ requests/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ all_openai_requests.jsonl       # Consolidated batch requests
‚îÇ   ‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ all_gpt5_responses.jsonl        # Consolidated GPT-5 responses
‚îÇ   ‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project_metadata.json           # Project statistics and metadata
‚îÇ   ‚îî‚îÄ‚îÄ tracking/
‚îÇ       ‚îî‚îÄ‚îÄ batch_info.json                 # Batch processing status
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îî‚îÄ‚îÄ questions.json                       # Original question dataset
‚îú‚îÄ‚îÄ üìÅ distortions/
‚îÇ   ‚îî‚îÄ‚îÄ chameleon_dataset.csv               # Final comprehensive dataset
‚îú‚îÄ‚îÄ üìÅ analysis_plots/                      # All visualizations and analysis
‚îÇ   ‚îú‚îÄ‚îÄ 1_subject_degradation_ranking.png   # Subject vulnerability ranking
‚îÇ   ‚îú‚îÄ‚îÄ 2_degradation_by_miu_level.png     # Œº level impact analysis
‚îÇ   ‚îú‚îÄ‚îÄ 3_degradation_distribution.png     # Degradation distribution
‚îÇ   ‚îú‚îÄ‚îÄ 4_degradation_progression.png      # Progression patterns
‚îÇ   ‚îú‚îÄ‚îÄ 5_subject_resilience_ranking.png   # Resilience ranking
‚îÇ   ‚îú‚îÄ‚îÄ 6_key_distortion_levels_heatmap.png # Key Œº levels heatmap
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_degradation_heatmap.png   # Complete degradation matrix
‚îÇ   ‚îú‚îÄ‚îÄ statistical_significance_distortion.png # McNemar test results
‚îÇ   ‚îú‚îÄ‚îÄ subject_significance_heatmap.png   # Subject significance analysis
‚îÇ   ‚îú‚îÄ‚îÄ mcnemar_distortion_results.csv     # Statistical test results
‚îÇ   ‚îú‚îÄ‚îÄ mcnemar_pairwise_results.csv       # Pairwise comparisons
‚îÇ   ‚îú‚îÄ‚îÄ mcnemar_subject_results.csv        # Subject-specific tests
‚îÇ   ‚îî‚îÄ‚îÄ Statistical_Analysis_Report.md     # Comprehensive statistical report
‚îú‚îÄ‚îÄ chameleon.py                            # Main orchestration script
‚îú‚îÄ‚îÄ gpt5_manager.py                        # GPT-5 batch management
‚îú‚îÄ‚îÄ monitor_repair.py                      # Monitoring and repair utilities
‚îú‚îÄ‚îÄ create_visualizations.py               # Visualization generation script
‚îú‚îÄ‚îÄ clean_gpt5_answers.py                  # Answer cleaning and validation
‚îú‚îÄ‚îÄ statistical_analysis.py                # McNemar's test implementation
‚îú‚îÄ‚îÄ Chameleon_Analysis_Report.md           # Main analysis report
‚îú‚îÄ‚îÄ requirements.txt                       # Core dependencies
‚îú‚îÄ‚îÄ requirements-dev.txt                   # Development dependencies
‚îú‚îÄ‚îÄ CONTRIBUTING.md                        # Contribution guidelines
‚îî‚îÄ‚îÄ LICENSE                                # MIT License
```

### Data Flow

```mermaid
graph LR
    A[Original Questions] --> B[Distortion Engine]
    B --> C[Batch Creator]
    C --> D[OpenAI API]
    D --> E[Response Processor]
    E --> F[Analysis Engine]
    F --> G[Reports & Visualizations]
```

## üîß System Functionality

### 1. Distortion Generation Strategy

The system applies controlled lexical distortions using **Mistral 7B Instruct v0.3** with a sophisticated Œº-to-temperature mapping formula that preserves semantic meaning while varying surface linguistic patterns.

#### **üìê Distortion Formula**

The core distortion strategy uses a **parametric Œº (mu) value** that controls intensity, mapped to Mistral's temperature using a custom formula:

```python
def calculate_temperature_from_miu(miu: float) -> float:
    """
    Œº ‚Üí Temperature mapping using exponential + sigmoid + paraphrase boost
    """
    # Base exponential component for growth
    exponential_component = 0.3 + (miu ** 1.5) * 1.2
    
    # Sigmoid component for smooth transitions
    sigmoid_boost = 0.3 * (1 / (1 + math.exp(-10 * (miu - 0.5))))
    
    # Strategic boost for high Œº values (paraphrase territory)
    paraphrase_boost = 0.0
    if miu >= 0.7:
        paraphrase_boost = 0.2 * ((miu - 0.7) / 0.3) ** 2
    
    # Combine and clamp to [0.1, 1.8]
    temperature = exponential_component + sigmoid_boost + paraphrase_boost
    return max(0.1, min(1.8, temperature))
```

#### **üéõÔ∏è Œº-Level Distortion Strategies**

| Œº Level | Temperature | Strategy | Description |
|---------|-------------|----------|-------------|
| **0.0** | 0.10 | No Distortion | Original question unchanged |
| **0.1** | 0.34 | Minimal Lexical | 1-2 word substitutions maximum |
| **0.2** | 0.50 | Light Lexical | Minor synonym replacements |
| **0.3** | 0.64 | Moderate Lexical | Word order changes + synonyms |
| **0.4** | 0.78 | Heavy Lexical | Complex substitutions + structure |
| **0.5** | 0.93 | Mixed Strategy | Lexical + light syntactic changes |
| **0.6** | 1.08 | Advanced Mixed | Syntactic restructuring + lexical |
| **0.7** | 1.24 | Heavy Mixed | Complex paraphrasing begins |
| **0.8** | 1.41 | Pre-Paraphrase | Near-complete reformulation |
| **0.9** | 1.59 | Full Paraphrase | Maximum creativity and change |

#### **ü§ñ Model Implementation**

**Base Model**: Mistral 7B Instruct v0.3  
**Prompt Strategy**: RLHF-optimized system prompt with strict guidelines  
**Generation Parameters**:
- Dynamic temperature based on Œº formula
- Top-p sampling: 0.9
- Max tokens: 2000-4000 (depending on batch size)
- Uniqueness validation: Every distortion must be completely unique

#### **üìù Example Distortion Progression**

**Original Question (Œº = 0.0):**
```
Which operator in Python carries out exponentiation?
A) **   B) ^   C) exp   D) pow
```

**Light Distortion (Œº = 0.3, temp = 0.64):**
```
Which operator in Python performs exponentiation?
A) **   B) ^   C) exp   D) pow
```

**Heavy Distortion (Œº = 0.9, temp = 1.59):**
```
In Python programming, what symbol is used to raise a number to a power?
A) **   B) ^   C) exp   D) pow
```

#### **üîí Semantic Preservation Rules**

1. **Answer Invariance**: Correct answer must remain the same
2. **Multiple Choice Integrity**: A/B/C/D options unchanged
3. **Factual Consistency**: No introduction of errors or contradictions
4. **Question Type Preservation**: What/How/Why structure maintained
5. **Domain Context**: Subject-specific terminology preserved when critical

### 2. Batch Processing Pipeline

The system efficiently processes large question sets using OpenAI's Batch API:

```python
# Automatic batch creation and submission
python3 gpt5_manager.py submit --auto

# Custom batch size
python3 gpt5_manager.py create --batch-size 100

# Monitor specific batches
python3 gpt5_manager.py monitor --ids batch_123 batch_124
```

### 3. Quality Assurance

- **Format Validation**: Ensures A/B/C/D response format
- **Duplicate Detection**: Removes redundant API calls
- **Error Recovery**: Automatic retry for failed requests
- **Completeness Check**: Validates 100% question coverage

### 4. Analysis Framework

Comprehensive statistical analysis with multiple dimensions:

```bash
# Generate all visualizations and analysis
python3 create_visualizations.py

# Clean GPT-5 answers and calculate accuracy
python3 clean_gpt5_answers.py

# Run comprehensive statistical analysis (McNemar's tests)
python3 statistical_analysis.py
```

**Generated Analysis Files:**
- **Visualizations**: 7 individual PNG plots showing degradation patterns
- **Statistical Tests**: McNemar's test results for distortion levels, subjects, and pairwise comparisons
- **CSV Reports**: Detailed statistical results with p-values and significance levels
- **Comprehensive Report**: `Chameleon_Analysis_Report.md` with complete findings

## üìö Usage Examples

### Example 1: Single Subject Analysis

```python
from modules.data_preparation import DistortionEngine
from modules.gpt5_batch_processor import BatchProcessor

# Initialize components
engine = DistortionEngine()
processor = BatchProcessor()

# Generate distortions for mathematics
questions = engine.load_subject("college_mathematics")
distorted = engine.apply_distortions(questions, miu_levels=[0.0, 0.3, 0.6, 0.9])

# Process with GPT-5
results = processor.process_batch(distorted)
print(f"Accuracy: {results.accuracy:.1f}%")
```

### Example 2: Custom Distortion Testing

```python
# Test specific distortion levels
custom_mius = [0.1, 0.25, 0.5, 0.75]
results = {}

for miu in custom_mius:
    distorted_questions = engine.apply_distortion(questions, miu=miu)
    result = processor.process_questions(distorted_questions)
    results[miu] = result.accuracy

# Plot results
import matplotlib.pyplot as plt
plt.plot(custom_mius, list(results.values()))
plt.xlabel('Distortion Level (Œº)')
plt.ylabel('Accuracy (%)')
plt.title('Custom Distortion Analysis')
plt.show()
```

### Example 3: Batch Monitoring

```python
from gpt5_manager import GPT5Manager

manager = GPT5Manager()

# Submit all pending batches
batch_ids = manager.submit_all_batches()

# Monitor with progress tracking
for batch_id in batch_ids:
    status = manager.monitor_batch(batch_id)
    print(f"Batch {batch_id}: {status.progress}% complete")
    
# Download results when complete
manager.download_all_results()
```

## üìä Configuration

### Main Configuration (`config/config.yaml`)

```yaml
settings:
  batch_split_percentage: 0.017
  max_batch_size: 80
  max_concurrent_workers: 2
  request_timeout: 600

subjects:
  - name: college_mathematics
    question_count: 910
    mius: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
  - name: professional_medicine
    question_count: 910
    mius: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
```

### API Configuration

```bash
# Required environment variables
export OPENAI_API_KEY="your-openai-api-key"
export OPENAI_ORG_ID="your-organization-id"  # Optional

# Optional: Custom endpoints
export OPENAI_BASE_URL="https://api.openai.com/v1"
```

## üìà Results and Analysis

### Performance Summary

| Metric | Value |
|--------|--------|
| **Total Questions** | 18,200 |
| **Overall Accuracy** | 85.8% |
| **Completion Rate** | 100% |
| **Valid Format Rate** | 97.4% |
| **Processing Time** | ~24 hours |

### Top Performing Subjects

1. **Professional Medicine**: 98.1% accuracy
2. **Medical Genetics**: 97.7% accuracy  
3. **High School Psychology**: 97.6% accuracy
4. **Astronomy**: 96.8% accuracy
5. **College Physics**: 96.6% accuracy

### Distortion Impact

| Œº Level | Accuracy | Degradation |
|---------|----------|-------------|
| 0.0 | 95.5% | 0.0% |
| 0.3 | 89.6% | 5.9% |
| 0.6 | 85.5% | 10.0% |
| 0.9 | 80.9% | 14.6% |

## üìä Statistical Analysis Results

### McNemar's Test Summary

My comprehensive statistical analysis using **McNemar's test for paired comparisons** reveals statistically significant performance degradation across multiple dimensions:

#### üéØ **Key Statistical Findings**
- **100% of distortion levels** show highly significant degradation (p < 0.001)
- **85% of academic subjects** exhibit significant vulnerability to lexical distortion
- **Strong statistical evidence** that GPT-5 relies on surface-level linguistic patterns
- **Non-linear degradation pattern** with distinct vulnerability thresholds

### üî¨ Distortion Level Analysis (vs Baseline Œº=0.0)

| Œº Level | Baseline Acc | Distorted Acc | Degradation | McNemar œá¬≤ | p-value | Significance |
|---------|--------------|---------------|-------------|------------|---------|--------------|
| **0.1** | 95.5% | 91.2% | **4.2%** | 45.52 | < 0.001 | *** |
| **0.2** | 95.5% | 89.3% | **6.2%** | 84.05 | < 0.001 | *** |
| **0.3** | 95.5% | 89.6% | **5.9%** | 74.40 | < 0.001 | *** |
| **0.4** | 95.5% | 88.7% | **6.8%** | 92.08 | < 0.001 | *** |
| **0.5** | 95.5% | 88.5% | **7.0%** | 96.61 | < 0.001 | *** |
| **0.6** | 95.5% | 85.5% | **10.0%** | 151.15 | < 0.001 | *** |
| **0.7** | 95.5% | 86.8% | **8.7%** | 125.75 | < 0.001 | *** |
| **0.8** | 95.5% | 81.5% | **14.0%** | 226.28 | < 0.001 | *** |
| **0.9** | 95.5% | 80.9% | **14.6%** | 240.57 | < 0.001 | *** |

> **Statistical Note**: All p-values < 0.001 indicate highly significant degradation. Even minimal distortion (Œº=0.1) causes statistically significant performance loss.

### üìö Subject Vulnerability Rankings

#### **Most Vulnerable Subjects** (Baseline vs Œº=0.9)
| Subject | Degradation | p-value | Significance |
|---------|-------------|---------|--------------|
| **Formal Logic** | **51.0%** | < 0.001 | *** |
| **Econometrics** | **48.0%** | < 0.001 | *** |
| **College Mathematics** | **36.0%** | < 0.001 | *** |
| **High School Computer Science** | **25.0%** | < 0.001 | *** |
| **Professional Law** | **18.0%** | < 0.01 | ** |

#### **Most Resilient Subjects**
| Subject | Degradation | p-value | Significance |
|---------|-------------|---------|--------------|
| **High School Biology** | **-2.0%** | 0.724 | Not significant |
| **Moral Disputes** | **-1.0%** | 1.000 | Not significant |
| **High School Psychology** | **3.0%** | 0.248 | Not significant |
| **College Biology** | **6.0%** | < 0.05 | * |
| **Marketing** | **6.0%** | < 0.05 | * |

### ‚ö° Critical Distortion Thresholds

#### **Significant Performance Drops** (Pairwise Œº Comparisons)
| Transition | Accuracy Drop | p-value | Significance |
|------------|---------------|---------|--------------|
| **Œº=0.0 ‚Üí 0.1** | **4.2%** | < 0.001 | *** |
| **Œº=0.1 ‚Üí 0.2** | **1.9%** | < 0.01 | ** |
| **Œº=0.5 ‚Üí 0.6** | **3.0%** | < 0.001 | *** |
| **Œº=0.7 ‚Üí 0.8** | **5.3%** | < 0.001 | *** |

#### **Stable Regions** (No Significant Change)
- **Œº=0.2 ‚Üí 0.5**: Plateau region with minimal degradation
- **Œº=0.8 ‚Üí 0.9**: Performance stabilizes at low accuracy

### üîç Statistical Interpretation

**McNemar's Test Results Indicate:**
1. **Surface Pattern Dependency**: Highly significant degradation across all distortion levels suggests GPT-5 relies heavily on exact wording patterns
2. **Domain-Specific Vulnerability**: Mathematical and logical reasoning subjects show extreme vulnerability (36-51% degradation)
3. **Non-Linear Degradation**: Performance drops occur in distinct thresholds rather than gradual decline
4. **Robustness Limits**: Even minimal lexical changes (Œº=0.1) cause statistically significant accuracy loss

**Confidence Level**: All reported significances use Œ± = 0.05 with Bonferroni correction for multiple comparisons.

> **‚ö†Ô∏è Critical Finding**: The statistical evidence strongly suggests that **GPT-5's high performance on academic benchmarks may partially stem from memorization of specific linguistic patterns** rather than pure reasoning capability.

## üî¨ Research Applications

### Academic Research

- **Model Robustness Studies**: Systematic evaluation of LLM resilience
- **Educational Assessment**: Validate AI tutoring systems
- **Benchmark Development**: Create robustness benchmarks for LLMs
- **Domain Analysis**: Study subject-specific model vulnerabilities

### Industry Applications

- **Quality Assurance**: Test production LLM deployments
- **A/B Testing**: Compare model versions under stress
- **Risk Assessment**: Evaluate model reliability for critical applications
- **Performance Monitoring**: Continuous robustness evaluation

## üõ†Ô∏è Development

### Adding New Subjects

```python
# 1. Add to config.yaml
subjects:
  - name: new_subject_name
    question_count: 910
    mius: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# 2. Prepare question data
python3 chameleon.py --add-subject new_subject_name

# 3. Generate distortions
python3 chameleon.py --subject new_subject_name --generate-distortions
```

### Custom Distortion Functions

```python
from modules.data_preparation import DistortionEngine

class CustomDistortionEngine(DistortionEngine):
    def apply_custom_distortion(self, text, intensity):
        # Implement custom distortion logic
        return modified_text

# Use custom engine
engine = CustomDistortionEngine()
results = engine.process_questions(questions, distortion_func=custom_func)
```

### Extending Analysis

```python
# Add custom metrics
from analysis import AnalysisFramework

framework = AnalysisFramework()
framework.add_metric("custom_score", custom_scoring_function)
framework.add_visualization("custom_plot", custom_plot_function)

# Generate extended report
framework.generate_report(include_custom=True)
```

## üìä Data Formats

### Input Question Format

```json
{
  "question_id": "math_001",
  "subject": "college_mathematics", 
  "topic": "calculus",
  "original_question": "What is the derivative of x¬≤?",
  "answer_options": {
    "A": "2x",
    "B": "x", 
    "C": "2x¬≤",
    "D": "x¬≤"
  },
  "correct_answer": "A",
  "difficulty": "medium"
}
```

### Output Results Format

```json
{
  "question_id": "math_001",
  "miu": 0.3,
  "distortion_index": 5,
  "distorted_question": "What represents the derivative of x¬≤?",
  "gpt5_answer": "A",
  "is_correct": true,
  "response_time": 1.2,
  "confidence": 0.95
}
```

## üîç Troubleshooting

### Common Issues

**Batch Processing Failures:**
```bash
# Check batch status
python3 gpt5_manager.py monitor --failed-only

# Repair failed batches
python3 monitor_repair.py --auto-repair

# Resubmit specific batches
python3 gpt5_manager.py submit --ids batch_123 batch_124
```

**API Rate Limits:**
```bash
# Adjust batch size
python3 gpt5_manager.py config --batch-size 50

# Add delays between requests
python3 gpt5_manager.py config --delay 0.5
```

**Memory Issues:**
```bash
# Process in smaller chunks
python3 chameleon.py --chunk-size 1000

# Enable memory optimization
python3 chameleon.py --optimize-memory
```

### Debugging

```bash
# Enable verbose logging
export CHAMELEON_DEBUG=1
python3 chameleon.py --verbose

# Check system resources
python3 -c "import psutil; print(f'Memory: {psutil.virtual_memory().percent}%')"

# Validate data integrity
python3 chameleon.py --validate-data
```

## üìã Requirements

### System Requirements

- **Python**: 3.9 or higher
- **Memory**: 8GB RAM minimum, 16GB recommended
- **Storage**: 5GB free space for datasets and results
- **Network**: Stable internet connection for API calls

### Python Dependencies

**Core Dependencies** (`requirements.txt`):
```txt
pandas>=1.5.0          # Data manipulation and analysis
numpy>=1.20.0           # Numerical computing
matplotlib>=3.5.0       # Data visualization
seaborn>=0.11.0         # Statistical data visualization
openai>=1.0.0           # OpenAI API client
pyyaml>=6.0             # Configuration file parsing
requests>=2.28.0        # HTTP library
tqdm>=4.64.0            # Progress bars
psutil>=5.9.0           # System monitoring
httpx>=0.25.0           # Async HTTP client
statsmodels>=0.14.0     # Statistical analysis (McNemar's test)
scipy>=1.10.0           # Scientific computing
```

**Development Dependencies** (`requirements-dev.txt`):
```txt
pytest>=7.0.0          # Testing framework
black>=23.0.0           # Code formatting
flake8>=6.0.0           # Code linting
mypy>=1.0.0             # Type checking
sphinx>=6.0.0           # Documentation generation
jupyter>=1.0.0          # Interactive notebooks
```

### API Requirements

- OpenAI API key with GPT-5 access
- Sufficient API credits for batch processing
- Organization permissions for batch API usage

## ü§ù Contributing

Contributions are welcome! Please see the [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone repository
git clone https://github.com/your-username/chameleon.git
cd chameleon

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Run tests
python3 -m pytest tests/

# Run linting
flake8 src/ tests/
black src/ tests/
```

### Submitting Changes

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- OpenAI for GPT-5 API access and batch processing capabilities
- Academic institutions providing question datasets
- Open source community for foundational tools and libraries
- Community feedback and testing support

## üî¨ Research Foundation

This project was inspired by the research presented in:

**"Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon"** by Cohen-Inger et al. ([ArXiv:2502.07445v2](https://arxiv.org/html/2502.07445v2))

While my implementation follows a different approach, I drew inspiration from their Chameleon Benchmark Overfit Detector (C-BOD) framework for systematic evaluation of language model robustness under textual perturbations. Their work highlighted the critical need for assessing model dependence on surface-level patterns versus genuine understanding.

**Key Differences in My Approach:**
- **Focus on GPT-5**: Specialized testing of OpenAI's latest model
- **Academic Domain Emphasis**: 20-subject curriculum-based evaluation
- **Parametric Distortion Control**: Fine-grained Œº-level distortion scaling (0.0-0.9)
- **Comprehensive Statistical Analysis**: McNemar's test and subject-specific significance testing
- **Production Pipeline**: Automated batch processing for large-scale studies

## üìö Citations

If you use Chameleon in your research, please cite:

```bibtex
@software{chameleon2024,
  title={Chameleon: GPT-5 Robustness Testing Framework},
  author={Steve Solun},
  year={2024},
  url={https://github.com/stevesolun/Chameleon}
}
```

## üó∫Ô∏è Future Ideas & Improvements

### üöÄ LLM Expansion
- [ ] **Multi-Provider Support**: Anthropic Claude, Google Gemini, Cohere, Llama
- [ ] **Model Comparison**: Side-by-side robustness analysis across different LLMs
- [ ] **API Standardization**: Unified interface for testing any language model
- [ ] **Local Model Support**: Integration with Ollama, Hugging Face Transformers

### üéØ Advanced Distortion Techniques
- [ ] **Semantic Distortions**: Meaning-preserving paraphrasing attacks
- [ ] **Syntactic Variations**: Grammar and sentence structure modifications
- [ ] **Adversarial Prompting**: Injection and jailbreaking resistance testing
- [ ] **Cultural/Linguistic Bias**: Cross-language and cultural sensitivity analysis

### üñºÔ∏è Multi-Modal Capabilities
- [ ] **Vision-Language Models**: Test robustness of GPT, Claude, Gemini, etc.
- [ ] **Image Distortions**: Visual noise, compression, style transfer effects
- [ ] **Mathematical Notation**: LaTeX equation parsing and distortion
- [ ] **Audio Processing**: Speech-to-text robustness analysis

### üèóÔ∏è Infrastructure & Scaling
- [ ] **Real-Time Processing**: Live distortion testing and monitoring
- [ ] **Distributed Computing**: Multi-node processing for large-scale studies
- [ ] **Cloud Integration**: AWS, GCP, Azure deployment templates
- [ ] **Auto-Scaling**: Dynamic resource allocation based on workload

### üìä Enhanced Analytics
- [ ] **Interactive Dashboards**: Web-based visualization and exploration
- [ ] **Statistical Significance**: Bayesian analysis and confidence intervals
- [ ] **Causal Analysis**: Understanding why certain distortions affect performance
- [ ] **Benchmark Suite**: Standardized robustness testing protocols

### üî¨ Research Applications
- [ ] **Educational Assessment**: Integration with learning management systems
- [ ] **Medical AI Safety**: Healthcare-specific robustness testing
- [ ] **Legal AI Compliance**: Regulatory and bias testing frameworks
- [ ] **Experiment Tracking**: MLflow, Weights & Biases integration

---

**Built with ‚ù§Ô∏è for the AI research community**