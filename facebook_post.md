# Facebook Post - Chameleon Project Key Findings

üß† **BREAKING: We just tested GPT-5's robustness across 18,200 questions and the results are fascinating!** 

Our "Chameleon Project" applied lexical distortions to questions across 20 academic subjects to see how AI performance degrades. Here's what we discovered:

üö® **MOST VULNERABLE**: Formal Logic took the biggest hit - a catastrophic 62% performance drop with moderate distortion! Logic and math subjects averaged 31% degradation.

üõ°Ô∏è **MOST RESILIENT**: Medical subjects like Biology actually *improved* under distortion (-5.4% degradation = better performance!). Medical fields averaged nearly zero degradation.

‚ö° **CRITICAL THRESHOLD**: Performance cliff at Œº=0.9 distortion level - 15.3% average drop across all subjects.

üìä **The Gap**: 31.5 percentage point difference between vulnerable (logic/math) and resilient (medical) domains.

This reveals something profound about how large language models process different types of knowledge. Medical reasoning appears more robust to linguistic variation than formal logical reasoning.

üî¨ **Full analysis with visualizations**: [Link to project]

#AI #GPT5 #MachineLearning #Research #ArtificialIntelligence #DataScience #AcademicResearch

---

**Technical Details:**
- 18,200 questions across 20 academic subjects
- 10 distortion levels (Œº=0.0 to 0.9)
- 100% completion rate
- Statistical significance across all domains
